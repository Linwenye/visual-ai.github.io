<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks">
  <meta name="keywords" content="Generalized Category Discovery, Visual Prompt">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/visailab.jpeg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script type="text/javascript" src="./static/js/copy.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://whj363636.github.io/">Hongjun Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://sgvaze.github.io/">Sagar Vaze</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.kaihan.org/">Kai Han</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Visual AI Lab, The University of Hong Kong</span>
            <br>
            <span class="author-block"><sup>2</sup>Visual Geometry Group, University of Oxford</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link.
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Visual-AI/Dissect-OOD-OSR"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="#Bib"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Citation</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
            <p>
                Detecting test-time distribution shift has emerged as a key capability for safely deployed machine learning models, with the question being tackled under various guises in recent years. In this paper, we aim to provide a consolidated view of the two largest sub-fields within the community: out-of-distribution (OOD) detection and open-set recognition (OSR). 
            </p>
            <p>
                In particular, we aim to provide rigorous empirical analysis of different methods across settings and provide actionable takeaways for practitioners and researchers. Concretely, we make the following contributions: 
            </p>            
            <p>
                (i) We perform rigorous cross-evaluation between state-of-the-art methods in the OOD detection and OSR settings and identify a strong correlation between the performances of methods for them; 
            </p>
            <p>
                (ii) We propose a new, large-scale benchmark setting which we suggest better disentangles the problem tackled by OOD detection and OSR, re-evaluating state-of-the-art OOD detection and OSR methods in this setting; 
            </p>
            <p>
                (iii) We surprisingly find that the best performing method on standard benchmarks (Outlier Exposure) struggles when tested at scale, while scoring rules which are sensitive to the deep feature magnitude consistently show promise; and (iv) We conduct empirical analysis to explain these phenomena and highlight directions for future research.
            </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Semantic shift <i>vs.</i> covariate shift</h2>
          <section class="hero teaser">
            <div class="container is-max-desktop">
              <div class="hero-body">
                <div class="col justify-content-center text-center">
                  <div class="col-sm-12">
                      <img src="static/images/teaser.png" style="width:60%">
                  </div>
                </div>
                  <!-- <img src="static/images/teaser.gif" alt="this slowpoke moves"/> -->
                  <p>We systematically perform cross-evaluation between SOTA methods for OSR and OOD detection and propose a large-scale benchmark setting in which we disentangle the tasks tackled in the two fields, proposing that they tackle <i>semantic shift</i> (x-axis) and <i>covariate shift</i> (y-axis) respectively.</p> 
              </div>
            </div>
          </section>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Cross-benchmarking of OOD detection and OSR methods</h2>
          <div class="col justify-content-center text-center">
          </div>
          <div class="content has-text-justified">
            <p>
            We benchmark OOD detection and OSR tasks across nine common datasets, with different training strategies and scoring rules. The results are averaged from five independent runs. Although there is not always one clear winner regarding methodology, we have three main observations.
            </p>
            <div class="col justify-content-center text-center">
                <div class="col-sm-12">
                    <center>
                    <img src="static/images/small_scale_main.png" style="width:95%">
                    </center>
                </div>
            </div>
            <p>
            Firstly, MLS and Energy tend to perform best across OOD and OSR datasets. This is because both are sensitive to the magnitude of the feature vector before the networksâ€™ classification layer.
            </p>
            <p>
            Secondly, Outlier Exposure provides excellent performance on the OOD detection benchmarks, often nearly saturating performance.
            </p>
            <p>
            Thirdly, for small-scale datasets, OOD detection accuracy is positively related to ID accuracy, while an inverse correlation is observed for large-scale datasets.
            </p>
            <div class="col justify-content-center text-center">
                <div class="col-sm-12">
                    <center>
                    <img src="static/images/clip.png" style="width:95%">
                    </center>
                </div>
            </div>
          </div>
        </div>
      </div>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="col justify-content-center text-center">
          </div>
          <div class="content has-text-justified">
            <p>
            We also evaluate a selection of previously discussed methods on our large-scale benchmark for both OOD detection and OSR. Through this large-scale evaluation, we find that <i>in terms of training methods, among CE, ARPL (+CS), and OE, there are no clear winners across the board</i>. It is surprising that the best performer on the previous small scale benchmarks, OE, appears to struggle when scaled up. 
            </p>
            <div class="col justify-content-center text-center">
                <div class="col-sm-12">
                    <center>
                    <img src="static/images/large_scale_main.png" style="width:95%">
                    </center>
                </div>
            </div> 
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Analysis</h2>
          <div class="content has-text-justified">
            <p>
            To analyze this further, we plot the distribution of maximum activation of the output feature (from the last layer) for samples from different data sources: ID data, OOD data, and auxiliary data. The results are shown below. 
            It is worth noting that the OOD detection performance strongly (negatively) correlates with the overlapped region of the ID and OOD curve. Additionally, when using 300K random images as auxiliary OOD data (as shown in the 2nd row), there is a high correlation with actual OOD data, resulting in excellent performance.
            </p>
            <div class="col justify-content-center text-center">
                <div class="col-sm-12">
                    <center>
                    <img src="static/images/oe_plot_small.png" style="width:95%">
                    </center>
                </div>
            </div>
            <p>
                We also provide results on a large-scale dataset. From the plot, the overlapping region is in line with the poor performance of OE on the large-scale benchmark. 
            </p>
            <div class="col justify-content-center text-center">
                <div class="col-sm-12">
                    <center>
                    <img src="static/images/oe_plot_large.png" style="width:95%">
                    </center>
                </div>
            </div>
            <p>
                We further retrieve nearest neighbors for the given samples on both small-scale (e.g., Textures and Places365) and large-scale (e.g., ImageNet-C and ImageNet-R) benchmarks using models trained by OE. By retrieving the nearest neighbors from the union of ID data and auxiliary data, we observe that for small-scale scenarios, the retrieved nearest neighbors are found in the auxiliary data. However, such phenomenon does not occur consistently in the large-scale datasets. This observation aligns with the correlation between the distance from OOD data to auxiliary data and the OOD detection performance of models trained using OE
            </p>
            <div class="col justify-content-center text-center">
                <div class="col-sm-12">
                    <center>
                    <img src="static/images/NN_yfcc.png" style="width:100%">
                    </center>
                </div>
            </div>
            <p>
                We compute the distance (denoted as OOD-AUX data distance) for both small-scale and large-scale OOD data, which further validates that closer proximity between auxiliary data and OOD data leads to better performance by OE models.
            </p>
            <div class="col justify-content-center text-center">
                <div class="col-sm-12">
                    <center>
                    <img src="static/images/dist_vs_per.png" style="width:95%">
                    </center>
                </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Metrics</h2>
          <div class="content has-text-justified">
            <p>
            Finally, we introduce a new metric to reconcile the problems of <i>detecting</i> covariate shift and being <i>robust</i> to it. AUROC does not capture the model's ability to reliably classify testing samples in the presence of distribution shifts. To analyze the relationship of performance between covariate shift and robustness, we introduce a novel measure, which we term <i>Outlier-Aware Accuracy</i> (OAA). OAA measures the frequency of `correct' predictions made by the model at a given threshold. The `correct' predictions are defined as: (1) Among the testing samples predicted as ID, those whose semantic class labels are \textit{correctly} predicted; (2) True OOD samples that have <i>incorrect</i> semantic class predictions.
            </p>
            <div class="col justify-content-center text-center">
                <div class="col-sm-12">
                    <center>
                    <img src="static/images/OAA.png" style="width:95%">
                    </center>
                </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="Bib">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
<pre><code id="BibTeX">@article{wang2024dissect,
    author    = {Wang, Hongjun and Vaze, Sagar and Han, Kai},
    title     = {Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks},
    journal = {International Journal of Computer Vision (IJCV)},
    year      = {2024}
}
</code><button class="copy-button" style="--button-hover-background: var(--example-color-alt); --button-color: var(--white); --button-background: var(--example-color-alt); --button-margin-bottom: 0;" class="copyButton btn" onclick="copyToClipboard('BibTeX','BibTeX_cop')"><i class="fa fa-copy"></i></button><p id="BibTeX_cop" style="display:none;color: #a0a0a0">Copied!</p></pre>
    </div>
  </section>

<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    This web page is modified based on the template from <a href="https://nerfies.github.io/">nerfies</a>. Thanks for their great work.
  </div>
</section>


</body>
</html>
